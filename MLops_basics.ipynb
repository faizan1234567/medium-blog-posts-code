{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "v7DGX6bB3121"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHtvCjU63fnQ"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import math\n",
        "import random\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def create_dataloader(is_train, batch_size, slice=5):\n",
        "    \"\"\"\n",
        "    Get a training dataloader for loading processed batched dataset for training\n",
        "    Args:\n",
        "      is_train: bool\n",
        "      batch_size: int\n",
        "      slice: int\n",
        "\n",
        "    return:\n",
        "      loader: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    full_dataset = torchvision.datasets.FashionMNIST(root=\".\", train=is_train, transform=T.ToTensor(), download=True)\n",
        "    sub_dataset = torch.utils.data.Subset(full_dataset, indices=range(0, len(full_dataset), slice))\n",
        "    loader = torch.utils.data.DataLoader(dataset=sub_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True if is_train else False,\n",
        "                                         pin_memory=True, num_workers=2)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = create_dataloader(is_train = True, batch_size = 32)\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "mKBXblWa3xkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self, in_channels: int = 1,\n",
        "               kernel_size: int= 3, stride:\n",
        "               int= 1, n_classes: int = 10,\n",
        "               dropout: float = 0.3):\n",
        "    \"\"\"Simple Neural network architecture for FashionMNIST classification\n",
        "\n",
        "    Args:\n",
        "      in_channels: int\n",
        "      kernel_size: int\n",
        "      stride: int\n",
        "      n_classes: int\n",
        "      dropout: float\n",
        "      \"\"\"\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.n_classes = n_classes\n",
        "    self.dropout = dropout\n",
        "    self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    self.model =  nn.Sequential(nn.Conv2d(self.in_channels, 16, kernel_size = self.kernel_size, stride = self.stride),\n",
        "                          nn.BatchNorm2d(16),\n",
        "                          nn.ReLU(),\n",
        "                          nn.MaxPool2d(kernel_size = 2),\n",
        "                          nn.Flatten(),\n",
        "                          nn.Linear(13 * 13 * 16, 256),\n",
        "                          nn.BatchNorm1d(256),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Dropout(self.dropout),\n",
        "                          nn.Linear(256, self.n_classes)).to(self.device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "fKdMG2uD4Foo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN(in_channels = 1, dropout = 0.4)"
      ],
      "metadata": {
        "id": "K9Lpv44_59V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8c-IoR97EBh",
        "outputId": "5736ddb4-a7d9-4979-f298-20fba1c023df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNN(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Flatten(start_dim=1, end_dim=-1)\n",
              "    (5): Linear(in_features=2704, out_features=256, bias=True)\n",
              "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.4, inplace=False)\n",
              "    (9): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_image_table(images, predicted, labels, probs):\n",
        "  \"\"\"\n",
        "  Create a log table for experiment comparison\n",
        "\n",
        "  Args:\n",
        "    images: torch.tensor\n",
        "    predicted: torch.tensor\n",
        "    labels: torch.tensor\n",
        "    probs: torch.tensor\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a wandb Table to log images, labels and predictions\n",
        "  table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(10)])\n",
        "  for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
        "      table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
        "  wandb.log({\"predictions_table\":table}, commit=False)"
      ],
      "metadata": {
        "id": "JxkATNKU-U8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
        "  \"\"\"\n",
        "  Compute performance of the model on the validation dataset and log a wandb.Table\n",
        "\n",
        "  Args:\n",
        "    model: torch.nn.Module\n",
        "    valid_dl: torch.utils.data.DataLoader\n",
        "    loss_func: torch.nn.BinaryCrossEntropy\n",
        "    log_images: bool\n",
        "    batch_idx: int\n",
        "\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  val_loss = 0.\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      for i, (images, labels) in enumerate(valid_dl):\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          # Forward propagation\n",
        "          outputs = model(images)\n",
        "          val_loss += loss_func(outputs, labels)*labels.size(0)\n",
        "\n",
        "          # Compute accuracy and accumulate\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "          # Log one batch of images to the dashboard, always same batch_idx.\n",
        "          if i==batch_idx and log_images:\n",
        "              log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
        "  return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)"
      ],
      "metadata": {
        "id": "EBRRKZJ27RP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch 3 experiments with different dropout rates\n",
        "for _ in range(3):\n",
        "    # initialise a wandb run\n",
        "    wandb.init(\n",
        "        project=\"Fashion-MNIST-Classification\",\n",
        "        config={\n",
        "            \"epochs\": 10,\n",
        "            \"batch_size\": 128,\n",
        "            \"lr\": 1e-3,\n",
        "            \"dropout\": random.uniform(0.01, 0.80),\n",
        "            })\n",
        "\n",
        "    # Copy your config\n",
        "    config = wandb.config\n",
        "\n",
        "    # Get the data\n",
        "    train_dl = create_dataloader(is_train=True, batch_size=config.batch_size)\n",
        "    valid_dl = create_dataloader(is_train=False, batch_size=2*config.batch_size)\n",
        "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
        "\n",
        "    # A simple MLP model\n",
        "    model = SimpleNN(in_channels=1, dropout=config.dropout)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "   # Training\n",
        "    example_ct = 0\n",
        "    step_ct = 0\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        for step, (images, labels) in enumerate(train_dl):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            train_loss = loss_func(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            example_ct += len(images)\n",
        "            metrics = {\"train/train_loss\": train_loss,\n",
        "                       \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch,\n",
        "                       \"train/example_ct\": example_ct}\n",
        "\n",
        "            if step + 1 < n_steps_per_epoch:\n",
        "                # Log train metrics to wandb\n",
        "                wandb.log(metrics)\n",
        "\n",
        "            step_ct += 1\n",
        "\n",
        "        val_loss, accuracy = validate(model, valid_dl, loss_func, log_images=(epoch==(config.epochs-1)))\n",
        "\n",
        "        # Log train and validation metrics to wandb\n",
        "        val_metrics = {\"val/val_loss\": val_loss,\n",
        "                       \"val/val_accuracy\": accuracy}\n",
        "        wandb.log({**metrics, **val_metrics})\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    # If you had a test set, this is how you could log it as a Summary metric\n",
        "    wandb.summary['test_accuracy'] = 0.8\n",
        "\n",
        "    # Close your wandb run\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a5EiU3q04YRB",
        "outputId": "1087627e-30cd-4db0-a090-e9a6e6852a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:bdxni39b) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clear-bush-3</strong> at: <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/bdxni39b' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/bdxni39b</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230814_164834-bdxni39b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:bdxni39b). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230814_165135-b8g86bwq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/b8g86bwq' target=\"_blank\">olive-energy-4</a></strong> to <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/b8g86bwq' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/b8g86bwq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.596, Valid Loss: 0.413211, Accuracy: 0.85\n",
            "Train Loss: 0.358, Valid Loss: 0.359685, Accuracy: 0.87\n",
            "Train Loss: 0.313, Valid Loss: 0.364193, Accuracy: 0.87\n",
            "Train Loss: 0.284, Valid Loss: 0.322773, Accuracy: 0.89\n",
            "Train Loss: 0.209, Valid Loss: 0.305100, Accuracy: 0.89\n",
            "Train Loss: 0.155, Valid Loss: 0.321308, Accuracy: 0.89\n",
            "Train Loss: 0.184, Valid Loss: 0.340890, Accuracy: 0.88\n",
            "Train Loss: 0.116, Valid Loss: 0.312305, Accuracy: 0.90\n",
            "Train Loss: 0.119, Valid Loss: 0.346075, Accuracy: 0.89\n",
            "Train Loss: 0.158, Valid Loss: 0.321600, Accuracy: 0.89\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/example_ct</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>█▆▆▄▅▄▃▃▂▄▂▃▃▂▃▂▂▂▂▂▃▂▂▂▂▁▂▂▂▁▂▂▁▁▁▂▁▂▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▄▄▇▇▇▅█▇█</td></tr><tr><td>val/val_loss</td><td>█▅▅▂▁▂▃▁▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/example_ct</td><td>120000</td></tr><tr><td>train/train_loss</td><td>0.15829</td></tr><tr><td>val/val_accuracy</td><td>0.8945</td></tr><tr><td>val/val_loss</td><td>0.3216</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">olive-energy-4</strong> at: <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/b8g86bwq' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/b8g86bwq</a><br/>Synced 5 W&B file(s), 1 media file(s), 257 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230814_165135-b8g86bwq/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mengrfaizan-ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230814_165313-kxcabfgl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/kxcabfgl' target=\"_blank\">spring-vortex-5</a></strong> to <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/kxcabfgl' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/kxcabfgl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.341, Valid Loss: 0.396059, Accuracy: 0.86\n",
            "Train Loss: 0.320, Valid Loss: 0.368896, Accuracy: 0.87\n",
            "Train Loss: 0.438, Valid Loss: 0.322818, Accuracy: 0.89\n",
            "Train Loss: 0.184, Valid Loss: 0.326449, Accuracy: 0.88\n",
            "Train Loss: 0.211, Valid Loss: 0.416485, Accuracy: 0.86\n",
            "Train Loss: 0.128, Valid Loss: 0.311538, Accuracy: 0.90\n",
            "Train Loss: 0.128, Valid Loss: 0.326986, Accuracy: 0.89\n",
            "Train Loss: 0.059, Valid Loss: 0.346680, Accuracy: 0.90\n",
            "Train Loss: 0.080, Valid Loss: 0.333361, Accuracy: 0.90\n",
            "Train Loss: 0.098, Valid Loss: 0.399065, Accuracy: 0.89\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/example_ct</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>█▆▆▅▄▄▄▃▃▄▃▃▂▃▂▃▁▂▂▂▂▂▁▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▃▆▆▂█▇▇█▇</td></tr><tr><td>val/val_loss</td><td>▇▅▂▂█▁▂▃▂▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/example_ct</td><td>120000</td></tr><tr><td>train/train_loss</td><td>0.09782</td></tr><tr><td>val/val_accuracy</td><td>0.8935</td></tr><tr><td>val/val_loss</td><td>0.39907</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">spring-vortex-5</strong> at: <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/kxcabfgl' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/kxcabfgl</a><br/>Synced 5 W&B file(s), 1 media file(s), 257 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230814_165313-kxcabfgl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230814_165446-2bn5umie</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/2bn5umie' target=\"_blank\">vocal-oath-6</a></strong> to <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/2bn5umie' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/2bn5umie</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.472, Valid Loss: 0.402348, Accuracy: 0.86\n",
            "Train Loss: 0.460, Valid Loss: 0.336740, Accuracy: 0.89\n",
            "Train Loss: 0.359, Valid Loss: 0.333175, Accuracy: 0.89\n",
            "Train Loss: 0.264, Valid Loss: 0.328039, Accuracy: 0.89\n",
            "Train Loss: 0.332, Valid Loss: 0.304157, Accuracy: 0.90\n",
            "Train Loss: 0.294, Valid Loss: 0.298192, Accuracy: 0.90\n",
            "Train Loss: 0.225, Valid Loss: 0.293916, Accuracy: 0.90\n",
            "Train Loss: 0.297, Valid Loss: 0.323904, Accuracy: 0.89\n",
            "Train Loss: 0.191, Valid Loss: 0.300282, Accuracy: 0.90\n",
            "Train Loss: 0.143, Valid Loss: 0.312663, Accuracy: 0.90\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/example_ct</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>█▅▆▄▃▃▄▄▃▂▃▃▃▂▂▂▂▃▂▂▂▂▂▂▃▂▂▁▁▂▁▂▂▁▁▂▁▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▆▅▅███▆█▇</td></tr><tr><td>val/val_loss</td><td>█▄▄▃▂▁▁▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/example_ct</td><td>120000</td></tr><tr><td>train/train_loss</td><td>0.14301</td></tr><tr><td>val/val_accuracy</td><td>0.8985</td></tr><tr><td>val/val_loss</td><td>0.31266</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vocal-oath-6</strong> at: <a href='https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/2bn5umie' target=\"_blank\">https://wandb.ai/engrfaizan-ai/Fashion-MNIST-Classification/runs/2bn5umie</a><br/>Synced 5 W&B file(s), 1 media file(s), 257 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230814_165446-2bn5umie/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}